{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 16:48:57.334098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-08 16:48:57.334173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_path = Path(\"../Images_for_Training\")\n",
    "label_names = [person.name for person in person_path.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maria' 'Nikhil' 'Simon']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(label_names)\n",
    "print(le.classes_)\n",
    "le.transform(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _565_to_channels(data: np.ndarray) -> np.ndarray:\n",
    "    width, height = data.shape\n",
    "    channels = np.zeros(shape=(width, height, 3), dtype=np.uint16)\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            pixel = data[x, y]\n",
    "            r = (pixel & 0xF800) >> 11 # F800: bits 11-15\n",
    "            g = (pixel & 0x07E0) >> 5  # 07E0: bits 5-10\n",
    "            b = (pixel & 0x1F)         # 001F: bits 0-4\n",
    "            channels[x, y, 0] = r\n",
    "            channels[x, y, 1] = g\n",
    "            channels[x, y, 2] = b\n",
    "\n",
    "    return channels\n",
    "\n",
    "\n",
    "def _565_to_888(data: np.ndarray) -> Image:\n",
    "    width, height = data.shape\n",
    "    img = Image.new('RGB', (width, height))\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            pixel = data[x, y]\n",
    "            r = (pixel & 0xF800) >> 11 # F800: bits 11-15\n",
    "            g = (pixel & 0x07E0) >> 5  # 07E0: bits 5-10\n",
    "            b = (pixel & 0x1F)         # 001F: bits 0-4\n",
    "            img.putpixel((x, y), (r * 8, g * 4, b * 8)) # multiply by (8, 4, 8) to scale back to [0,255]\n",
    "\n",
    "    return img\n",
    "\n",
    "def _888_to_565(im: Image) -> np.ndarray:\n",
    "    width, height = im.size\n",
    "    new_pxs = np.zeros(shape=(width, height), dtype=np.uint16)\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            r, g, b = im.getpixel((x,y))\n",
    "\n",
    "            # downsample to RGB565\n",
    "            r //= 8\n",
    "            g //= 4\n",
    "            b //= 8\n",
    "            new_pxs[x, y] = (r << 11) | (g << 5) | b\n",
    "\n",
    "    return new_pxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:19,  4.61it/s]\n",
      "98it [00:20,  4.69it/s]\n",
      "72it [00:14,  4.92it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "data = []\n",
    "for person in person_path.iterdir():\n",
    "    for file in tqdm(person.iterdir()):\n",
    "        if str(file).endswith(\".npy\"):\n",
    "            img_np = np.load(file)\n",
    "\n",
    "            img = _565_to_888(img_np)\n",
    "            img = img.resize((120, 160))  ## scale to lowest res\n",
    "            \n",
    "            img_np = _888_to_565(img) # go back to 565, as Arduino will use this\n",
    "            #print(np.shape(img_np))\n",
    "            #plt.imshow(img_np)\n",
    "            img_np = _565_to_channels(img_np)\n",
    "            #print(img_np.shape)\n",
    "            #plt.imshow(img_np)\n",
    "\n",
    "            data.append(img_np)\n",
    "            labels.append(le.transform([person.name])[0])\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "\n",
    "#w = 10\n",
    "#h = 10\n",
    "#fig = plt.figure(figsize=(8, 8))\n",
    "#columns = 4\n",
    "#rows = 5\n",
    "#for i in range(1, columns*rows +1):\n",
    "#    img = data[np.random.randint(len(data))]\n",
    "#    fig.add_subplot(rows, columns, i)\n",
    "#    plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130,)\n",
      "(130, 120, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 49, 0: 45, 1: 36})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the transformed data as ready to use tensor and labels, with classes that can be loaded to labelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Images_Transformed_565_160_120/data.npy\", \"wb\") as f:\n",
    "    np.save(f, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Images_Transformed_565_160_120/labels.npy\", \"wb\") as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Images_Transformed_565_160_120/classes.npy\", \"wb\") as f:\n",
    "    np.save(f, le.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0088029b3bf0883d79fb316fdd34e9e1ba6cd66820b181ce01ee6eba35b10f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
